##  2002 年-2018 年上海机动车拍照拍卖

```python
import pandas as pd 
import numpy as np 
df =pd.read_csv('data/2002年-2018年上海机动车拍照拍卖.csv')
df.head(3)
```

### (1) 哪一次拍卖的中标率首次小于 5%？

```python
df.groupby(df['Total number of license issued']/df['Total number of applicants']<0.05).first()
## 15-May 中标率首次小于5%
```

### (3) 将第一列时间列拆分成两个列，一列为年份（格式为 20××），另一列为月份（英语缩写），添加到列表作为第一第二列，并将原表第一列删除，其他列依次向后顺延。


```python
df['year']=df.Date.apply(lambda x:'20'+x.split('-')[0] if int(x.split('-')[0])>=10 else  '200'+x.split('-')[0] )
df['month']=df.Date.apply(lambda x:x.split('-')[1])
df=df.iloc[:,[5,6,1,2,3,4]]
```

```python
df.head(3)
```

### (2) 按年统计拍卖最低价的下列统计量：最大值、均值、0.75 分位数，要求显示在同一张表上。

```python
q75 = lambda x:x.quantile(0.75)
df.groupby('year').agg({'lowest price ':['mean','max',q75]})
```

### (4) 现在将表格行索引设为多级索引，外层为年份，内层为原表格第二至第五列的变量名，列索引为月份。


```python
df.set_index(['year','Total number of license issued', 'lowest price ',
       'avg price', 'Total number of applicants'])
```

### (5) 一般而言某个月最低价与上月最低价的差额，会与该月均值与上月均值的差额具有相同的正负号，哪些拍卖时间不具有这个特点？

```python
df.loc[df['lowest price '].diff().fillna(0)*df['avg price'].diff().fillna(0)<0,['year','month']] 
```

### (6) 将某一个月牌照发行量与其前两个月发行量均值的差额定义为发行增益，最初的两个月用 0 填充，求发行增益极值出现的时间。

```python
df['gain'] =(df['Total number of license issued'].diff()+ df['Total number of license issued'].diff(2)).fillna(0)/2
##极大增益
df.loc[df.gain==df.gain.max(),['year','month']] 
##2008, Jan
```

```python
##极小增益
df.loc[df.gain==df.gain.min(),['year','month']] 
##2008, Apr
```

## 2007 年-2019 年俄罗斯机场货运航班运载量

```python
df2 = pd.read_csv('data/2007年-2019年俄罗斯货运航班运载量.csv')
df2.head(3)
```

### (1) 求每年货运航班总运量

```python
df2.groupby('Year')['Whole year'].sum()
```

### (2) 每年记录的机场都是相同的吗

```python
tmp=pd.DataFrame(df2.groupby(['Year','Airport name'])['Airport coordinates'].count()).reset_index()
tmp.pivot(index='Airport name',columns='Year',values='Airport coordinates')
##行索引为全部航班，列为各年份，NAN的地方即是该年分没有记录的航班
##所以并不是相同的
```

### (3) 按年计算 2010 年-2015 年全年货运量记录为 0 的机场航班比例。

```python
df2.groupby('Year').apply(lambda x:(x['Whole year']==0).sum()/x['Whole year'].count())[3:9]
```

### (4) 若某机场至少存在 5 年或以上满足所有月运量记录都为 0，则将其所有年份的记录信息从表中删除，并返回处理后的表格


```python
tmp2=  df2.groupby('Airport name').apply(lambda x:(x['Whole year']==0).sum())
tmp3 =list(tmp2[tmp2>=5].index)
df2[~df2['Airport name'].isin(tmp3)]
```

### (5) 采用一种合理的方式将所有机场划分为东南西北四个分区，并给出 2017年-2019 年货运总量最大的区域。

```python
import re
fc= lambda x: re.search("\d+(\.\d+)?",x).group() if x!='' else x 
```

```python
df2['longitude']=df2['Airport coordinates'].apply(lambda x:fc(x.split(',')[0] if x!='Not found' else '' ))
df2['latitude']=df2['Airport coordinates'].apply(lambda x:fc(x.split(',')[1] if x!='Not found' else '' ))

##缺失值填充
df2['longitude']=df2['longitude'].apply(lambda x : np.nan if x=='' else x ).fillna(method='bfill').astype('float')
df2['latitude']=df2['latitude'].apply(lambda x : np.nan if x=='' else x ).fillna(method='bfill').astype('float')
```

```python
m1,m2=df2.longitude.median(),df2.latitude.median()
```

```python
df2['region']=''
df2.loc[(df2.longitude<=m1)&(df2.latitude>m2),'region']='NW'
df2.loc[(df2.longitude<m1)&(df2.latitude<=m2),'region']='SW'
df2.loc[(df2.longitude>=m1)&(df2.latitude>m2),'region']='NE'
df2.loc[(df2.longitude>m1)&(df2.latitude<=m2),'region']='SE'
```

```python
df2.loc[(df2.Year>=2017)&(df2.Year<=2019),:].groupby('region')['Whole year'].sum()
##西南部 运货总量最大 区域为 ##[[6.22,82.049),[8.60,58.18])
#NE     125712.21
#NW     134528.40
#SE     391377.92
#SW    1653745.30
```

### (6) 在统计学中常常用秩代表排名，现在规定某个机场某年某个月的秩为该机场该月在当年所有月份中货运量的排名（例如 *** 机场 19 年 1 月运量在整个 19 年 12 个月中排名第一，则秩为 1），那么判断某月运量情况的相对大小的秩方法为将所有机场在该月的秩排名相加，并将这个量定义为每一个月的秩综合指数，请根据上述定义计算 2016 年 12 个月的秩综合指数。


```python
tmp4=df2.loc[df2.Year==2016]
tmp5=tmp4.melt(id_vars=['Airport name'],value_vars=[i for i in tmp4.columns[2:14]],value_name='values').rename(columns={'variable':'month'})
tmp5['rank']=tmp5['values'].groupby(tmp5['Airport name']).rank(method='min') ##获取飞机每月排名，相同排序时取得小值
tmp5.groupby('month')['rank'].sum()

```

## 新冠肺炎在美国的传播

```python
df_c = pd.read_csv('data/美国确证数.csv')
df_c.head(3)
```

```python
df_d = pd.read_csv('data/美国死亡数.csv')
df_d.head(3)
```

### (1) 用 corr() 函数计算县（每行都是一个县）人口与表中最后一天记录日期死亡数的相关系数。


```python
df_d[['Population', '2020/4/26']].corr()
##相关系数0.4038，有比较明显的相关性了
```

### (2) 截止到 4 月 1 日，统计每个州零感染县的比例。

```python
tmp6= df_c.melt(id_vars=['Province_State','Admin2'],value_vars=[i for i in df_c.columns[11:82]],value_name='diags').rename(columns={'variable':'month'})\
        .groupby(['Province_State','Admin2']).diags.sum().groupby('Province_State').apply(lambda x:(x==0).sum()/x.count())
tmp6
```

### (3) 请找出最早出确证病例的三个县。

```python
tmp7= df_c.melt(id_vars=['Province_State','Admin2'],value_vars=[i for i in df_c.columns[11:82]],value_name='diags').rename(columns={'variable':'date'})\
        .groupby(['Province_State','Admin2','date']).apply(lambda x:x['diags'].cumsum())

tmp7[tmp7>0].reset_index().groupby(['Province_State','Admin2']).head(1).sort_values(by='date')[:3]

##King：1.22，Cook：1.24，Orange：1.26
##23812	Washington	King	2020/1/22	2969	1
##6068	Illinois	Cook	2020/1/24	6894	1
##1829	California	Orange	2020/1/26	12783	1
```

### (4) 按州统计单日死亡增加数，并给出哪个州在哪一天确诊数增加最大（这里指的是在所有州和所有天两个指标一起算，不是分别算）。

```python

```
