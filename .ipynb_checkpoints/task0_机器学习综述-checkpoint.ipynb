{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>机器学习介绍</b>\n",
    "    \n",
    "- 机器学习是什么：\n",
    "  - 机器学习是关于计算机基于数据构建概率统计模型并运用模型对数据进行预测与分析的一门学科或者技术。\n",
    "\n",
    "- 机器学习的目的\n",
    "  - 对于数据进行预测与分析，特别是对未知的新数据进行预测与分析。对数据的预测可以使计算机更加智能化，或者说使计算机的性能得到提高；对数据的分析可以使人们获得新的知识，给人们带来新的发现。对数据的预测分析是通过构建概率模型实现的，统计学习总的目标是考虑学习什么样的模型和如何学习模型，以使模型能对数据进行准确的预测与分析，同时尽可能地提高效率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>机器学习分类</b>\n",
    "\n",
    "- **按照学习方法来分**\n",
    "- 监督学习：\n",
    "  - 训练的数据是有标签的，有监督学习的目的在于学习一个从输入空间$\\mathcal{X}$到输出空间 $\\mathcal{Y}$ 的映射 $f$ ,或是条件概率 $𝑃(𝑌|𝑋)$。\n",
    "- 无监督学习：  \n",
    "  - 训练数据是没有标签的，目标是通过对无标记训练样本的学习来揭示数据的内在性质及规律。\n",
    "- 半监督学习：\n",
    "  - 是监督学习与无监督学习相结合的一种学习方法。半监督学习使用大量的未标记数据，以及同时使用标记数据，来进行模式识别工作。当使用半监督学习时，将会要求尽量少的人员来从事工作，同时，又能够带来比较高的准确性。\n",
    "  \n",
    "- **按照任务类型分来分**\n",
    "- 回归：输出变量Y取值连续\n",
    "- 分类：输出变量Y取值有离散个\n",
    "  - **生成模型与判别模型**\n",
    "  - 生成模型\n",
    "    > 1. 生成方法通过学习数据得到联合概率分布P(X,Y),然后求出条件概率分布P(Y|X)作为预测的模型，即生成模型：$P(Y|X)= \\dfrac{P(X,Y)}{P(X)}$。\n",
    "    > 2. 这样的方法之所以叫生成方法，是因为模型表示了输入X产生的输出Y的生成关系。典型的生成模型有：朴素贝叶斯和隐马尔科夫链。\n",
    "    > 3. 生成模型特点：a.可以还原出联合概率分布$P(X,Y)$;b.学习收敛速度快，即当样本容量增加的时候，学习到的模型可以更快的收敛于真实模型；c.当存在隐变  量时，仍可以用生成学习方法。\n",
    "  - 判别模型\n",
    "    >1. 判别方法由数据直接学习决策函数$f(X)$或者条件概率分布$P(Y|X)$作为预测的模型，即判别模型。\n",
    "    >2. 判别方法关心的是对给定的输入X，应该预测出什么样的Y。典型的判别模型：K紧邻，感知机，决策树，逻辑回归、最大熵模型、SVM,提升方法和条件随机场等。\n",
    "    >3. 判别模型特点：a.直接学习的是条件概率$P(Y|X)$,或决策函数$f(X)$,直接面对预测，学习效率高。b.由于直接学习$P(Y|X)$或$f(X)$，可以对数据进行各种程度上的抽象、定义特征并使用特征，因此可以简化学习问题。\n",
    "- 聚类\n",
    "- 降维\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>机器学习方法三要素</b>\n",
    " \n",
    " *机器学习 = 模型 + 策略 +优化算法*\n",
    " \n",
    "- 模型：\n",
    " > 模型的假设空间：输入空间到输出空间映射的集合。这一映射由模型来表示。假设空间通常是由一个参数向量决定的函数族，所以假设空间 是学习模型的集合。\n",
    "- 策略：\n",
    "> 有了模型的假设空间，需要考虑按照什么样的准则选择最优的模型。\n",
    "> 损失函数：度量模型一次预测的好坏.\n",
    "> 风险函数：度量平均意义下模型预测的好坏。\n",
    "- 优化算法：\n",
    "> 指的是模型的具体计算方法。机器学习 基于训练集，根据学习策略，从假设空间中选择最优模型，最后需要考虑用什么样的计算方法求解最优模型。此时，机器学习问题成为最优化问题。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>策略</b>\n",
    "\n",
    "- 损失函数：\n",
    "\n",
    "  - 是用来评估模型的预测值$f(x)$与真实值$Y$的不一致程度，它是一个非负实值函数，通常用$L(Y,f(x))$来表示。损失函数是经验风险函数的核心部分，也是结构风险函数的重要组成部分（另外还包含正则项）。\n",
    "\n",
    " - 常见的损失函数：\n",
    "    > 1. 0-1损失函数$I(Y \\not = f(X))$\n",
    "    > 2. 绝对损失函数$L(Y,f(X))=|Y-f(X)|$\n",
    "    > 3. 平方损失函数：$L(Y,f(X))=(Y-f(X))^2$\n",
    "    > 4. 对数损失函数$L(Y,P(Y|X))=-logP(Y|X)$\n",
    " \n",
    "- 风险函数：\n",
    "  - 结构风险：在经验风险的基础上添加表征模型复杂度的正则部分  $R_{str}= \\dfrac{1}{N} \\sum_{i=1}^{N} L \\left(y_{i}, f \\left( \\mathbf{x}_{i} \\right) \\right) + \\lambda J \\left(f\\right)$。\n",
    "  - 经验风险$R_{emp}{f}=\\dfrac{1}{N} \\sum_{i=1}^{N} L \\left(y_{i}, f \\left( \\mathbf{x}_{i} \\right) \\right)$是：在给定数据集和损失函数的情况下，模型 $f(X)$关于训练集的平均损失，在训练样本足够大时，经验风险趋近于期望风险，可以用经验风险来估计期望风险。但是现实中的训练样本是有限的，用经验风险来估计期望风险是不准确的，因此需要对经验风险进行矫正---加上表征模型复杂的正则化项$J \\left(f\\right)$。\n",
    "   > $J \\left(f\\right)$是模型复杂度，是正则化项，是定义在假设空间$\\mathcal{F}$上的泛函；$\\lambda \\geq 0$是系数，用以权衡风险和模型复杂度。\n",
    "当模型$f$越复杂，复杂度$J \\left(f\\right)$就越大，反之模型越简单，$J \\left(f\\right)$就越小。也就是说，复杂度表示了对复杂模型的惩罚。$\\lambda$是惩罚系数，用以权衡经验风险和模型复杂度。结构风险小的模型，需要经验风险与结构风险同时小，这样的模型往往对训练数据和未知的测试数据都能够有较好的预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>优化算法</b>\n",
    "- 梯度下降是最常用的优化方法之一，它使用梯度的反方向$\\nabla_\\theta J(\\theta)$更新参数$\\theta$，使得目标函数$J(\\theta)$达到最小化的一种优化方法，这种方法我们叫做梯度更新.\n",
    "\n",
    "> (全量)梯度下降 $$ \\theta=\\theta-\\eta\\nabla_\\theta J(\\theta) $$\n",
    "> 随机梯度下降 $$ \\theta=\\theta-\\eta\\nabla_\\theta J(\\theta;x^{(i)},y^{(i)}) $$\n",
    "> 小批量梯度下降 $$ \\theta=\\theta-\\eta\\nabla_\\theta J(\\theta;x^{(i:i+n)},y^{(i:i+n)}) $$\n",
    "> 引入动量的梯度下降 $$ \\begin{cases} v_t=\\gamma v_{t-1}+\\eta \\nabla_\\theta J(\\theta) \\ \\theta=\\theta-v_t \\end{cases} $$\n",
    "> 自适应学习率的Adagrad算法 $$ \\begin{cases} g_t= \\nabla_\\theta J(\\theta) \\ \\theta_{t+1}=\\theta_{t,i}-\\frac{\\eta}{\\sqrt{G_t+\\varepsilon}} \\cdot g_t \\end{cases} $$\n",
    "> 牛顿法 $$ \\theta_{t+1}=\\theta_t-H^{-1}\\nabla_\\theta J(\\theta_t) $$ \n",
    "\n",
    "其中: $t$: 迭代的轮数\n",
    "$\\eta$: 学习率\n",
    "$G_t$: 前t次迭代的梯度和\n",
    "$\\varepsilon:$很小的数,防止除0错误\n",
    "$H$: 损失函数相当于$\\theta$的Hession矩阵在$\\theta_t$处的估计"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>模型选择</b>\n",
    "\n",
    "当假设空间有多个不同复杂度的模型时，需要面临模型选择。如果一味提高对训练数据的预测能力，所选择的模型复杂度往往过高，会出现过拟合现象。\n",
    "模型选择的方法：\n",
    "- 正则化：是结构风险最小化策略的实现，前面已写。\n",
    "- 交叉验证 ：随机将数据集划分成训练集、验证集、测试集。训练集用来训练模型，验证集用于模型的选择，测试集用来对最终学习效果的评估。在学习到的不同复杂度的模型中，选择对验证集最小预测误差的模型。但是如果数据不是很多，需要进行交叉验证-重复使用数据的方法：将原数据集组合为训练集和测试集，在此基础上反复的进行训练、测试及模型选择。\n",
    ">1. 简单交叉验证：首先随机的将已给数据划分成两部分，一部分作为训练集，一部分作为测试集；然后用训练集在各种条件下训练模型，在测试集上评价各个模型的误差，选出测试误差最小的模型。\n",
    ">2. S折交叉验证：随机的将已给的数据切分为S个互不相交的大小相同的子集，然后利用S-1个子集的数据训练模型，利用剩下的一个测试模型，将这一过程重复进行S次，最后选出评测中平均误差最小的模型。\n",
    ">3. 留一交叉验证：S折交叉验证中S=N时，为留一交叉验证，适用于小样本，数据缺乏的情况。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-07T13:54:31.176736Z",
     "start_time": "2020-01-07T13:54:31.167761Z"
    }
   },
   "source": [
    "<b>范数</b>\n",
    "\n",
    "- 范数是一个强化了的距离概念，存在的意义是为了现实比较。\n",
    "- 在一维实数集合中，很直观的2比1大；但在二维空间中，对于不可比较大小的两个点(1,2),(0,3)，通过2范数(平方和再开平方根)，将他们映射为实数$\\sqrt{5}$和3，也可以进行大小比较。\n",
    "- 同样，在更高维的向量空间中，都可以通过范数将不可比较的向量转化为可比较的实数。\n",
    "- 但是向量在一个空间里的长度表示可以有很多种，可以公式化的表示为  $\\left \\| x \\right \\|_{p} = ( \\sum_{i=1}^{n}  x_{i}^{p})^{\\frac{1}{p}}$,p即为范数。\n",
    "\n",
    "\n",
    "- L1、L2范数\n",
    ">1. L1范数，当p=1时， $\\left \\| x \\right \\|_{1} =  \\sum_{i=1}^{n}|x_{i}|$,表示向量x中非0元素的绝对值之和。\n",
    ">2. L2范数，当p=2时，$\\left \\| x \\right \\|_{2} = ( \\sum_{i=1}^{n}  x_{i}^{2})^{\\frac{1}{2}}$，表示向量的平方和再开平方。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>模型评价</b>\n",
    "- 回归：\n",
    "> MSE(Mean Squared Error) $$ MSE(y,f(x))=\\frac{1}{N}\\sum_{i=1}^{N}(y-f(x))^2 $$\n",
    "> MAE(Mean Absolute Error) $$ MSE(y,f(x))=\\frac{1}{N}\\sum_{i=1}^{N}|y-f(x)| $$\n",
    "> RMSE(Root Mean Squard Error) $$ RMSE(y,f(x))=\\frac{1}{1+MSE(y,f(x))} $$\n",
    "\n",
    "- 分类：\n",
    "> 准确率(Accuracy) $$ ACC=\\frac{TP+TN}{TP+FN+FP+TN} $$\n",
    "> 精准率 $$ P=\\frac{TP}{TP+FP} $$\n",
    "> 召回率 $$ R=\\frac{TP}{TP+FN} $$\n",
    "> F1-Score $$ \\frac{2}{F_1}=\\frac{1}{P}+\\frac{1}{R} $$\n",
    "> ROC：ROC曲线的横轴为“假正例率”，纵轴为“真正例率”. 以FPR为横坐标，TPR为纵坐标，那么ROC曲线就是改变各种阈值后得到的所有坐标点 (FPR,TPR) 的连线，画出来如下。红线是随机乱猜情况下的ROC，曲线越靠左上角，分类器越佳.\n",
    "> AUC(Area Under Curve)：AUC就是ROC曲线下的面积. 真实情况下，由于数据是一个一个的，阈值被离散化，呈现的曲线便是锯齿状的，当然数据越多，阈值分的越细，”曲线”越光滑."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>机器学习参数调优</b>\n",
    "\n",
    "- 网格搜索\n",
    ">一种调参手段；穷举搜索：在所有候选的参数选择中，通过循环遍历，尝试每一种可能性，表现最好的参数就是最终的结果\n",
    "\n",
    "- 随机搜索\n",
    ">与网格搜索相比，随机搜索并未尝试所有参数值，而是从指定的分布中采样固定数量的参数设置。它的理论依据是，如果随即样本点集足够大，那么也可以找到全局的最大或最小值，或它们的近似值。通过对搜索范围的随机取样，随机搜索一般会比网格搜索要快一些。\n",
    "\n",
    "- 贝叶斯优化算法\n",
    ">给定优化的目标函数(广义的函数，只需指定输入和输出即可，无需知道内部结构以及数学性质)，通过不断地添加样本点来更新目标函数的后验分布(高斯过程,直到后验分布基本贴合于真实分布。简单的说，就是考虑了上一次参数的信息，从而更好的调整当前的参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " -- https://www.jianshu.com/p/4ef549eb0ad4 生成模型与判别模型\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
